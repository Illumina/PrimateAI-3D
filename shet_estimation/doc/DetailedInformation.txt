
Forward-time simulation of human population expansion
The current prevalence of a mutation is shaped by its evolutionary dynamics, and typically, more harmful mutations tend to be less common. During the course of evolution, new genetic variants arise due to de novo mutation, while natural selection removes others. In the context of a constant human population size, the allele frequencies of these deleterious variants would eventually reach an equilibrium point136. However, the human population size has grown exponentially, which has impacted the frequencies of detrimental alleles54,55. Therefore, we used forward time simulation to model the effects of the two forces on the distribution of allele frequencies of variants.

We first simulated a forward-time population expansion model under the assumption of neutral evolution.  Our model simplified the evolutionary trajectory of human population, dividing it into four phases of exponential expansion, each characterized by a different growth rate. We began with the initial effective population size, denoted as Ne0, of 10,000 individuals. We assumed the ratio between the census population size and the effective population size remains constant throughout human history, denoted as r. Additionally, we considered a generation time of 30 years.

We initiated the simulation with a burn-in phase spanning 3,500 generations (Fig. 1c), during which we introduced a slight alteration in the effective population size. We denoted the population size change ratio as n. This extended burn-in was employed to replicate the bottleneck effect experienced by the human population during the ice age. Given the uncertainty regarding the specific time at the conclusion of the burn-in phase, we designated this moment as T1. At T1, the effective population size at T1 was 10,000*2*n (considering the diploid nature of the human genome). The per-generation population expansion rate during the burn-in period is n^(1/3500).

In the year1400 CE, the estimated human census population size was approximately 360 million137-139. We calculated the number of generations between T1 and 1400 CE as (1400-T1)/30, denoted as g.  The per-generation population growth rate during this stage between T1 and 1400 CE was computed as (3.6/r/n) ^(1/g).

By the year1700 CE, the global census population had grown to about 620 million137-139. Calculating the number of generations that passed between 1400 CE and 1700 CE as 10, the population growth rate during this period was (6.2/3.6)^(1/10).

In the year 2000 CE, the worldwide census population reached 6.2 billion, marking a tenfold increase from 1700 CE. Over these ten generations, the growth rate was (10)^(1/10).  

In addition to this basic demographic model, we also designed a more complex model, dividing the human population evenly into five subpopulations representing African, European, American, South Asian, and East Asian populations (Extended Data Fig. 1b). This partitioning took place at T1, which marked the conclusion of the burn-in phase. Over the subsequent three phases of exponential expansion, these five subpopulations evolve independently, without any migration between them. 

Since we maintain well-estimated census population sizes, our goal is to determine three specific parameters: the ratio of the census population size to the effective population size (r), the number of generations that elapsed between T1 and the year 1400 CE (g), and the ratio between the effective population size at time T1 and Ne0 (n). Therefore, this model's simulation seeks to optimize these three demographic parameters (r, g, and n).

As we focused on rare mutations, we initialized our simulation with all chromosomes fixed for the ancestral allele. Subsequently, in each generation, the population size expanded according to the growth rate and chromosomes were sampled uniformly at random from the prior generation. De novo mutations were introduced onto these chromosomes based on de novo mutation rates derived from three large parental-offspring trio datasets with whole genome sequencing, including the Halldorsson set115 (2,976 trios), the Goldmann set116 (1,291 trios), and the Sanders set117 (3,804 trios). By combining data from these 8,071 trios, we identified de novo mutations mapped to intergenic regions, with which we estimated the mutation rates for each of the 192 trinucleotide context configurations68. Note that the Spearman correlation between our estimates of de novo mutation rates and gnomAD de novo mutation rates68 is 0.9991, but our estimates tend to be slightly lower at the CpG sites.

Considering the substantial influence of methylation levels at CpG sites on mutation rates140, it's imperative to incorporate methylation levels into our model for modeling CpG transition mutation rates. First, we evaluated the impact of methylation levels on CpG mutation rates using whole genome bisulfite sequencing data provided by the Roadmap Epigenomics project118. We extracted methylation data for each CpG island, averaging the values across 10 embryonic stem cell (ESC) samples.  These CpG islands were then divided into ten decile bins based on their respective methylation levels. We tallied the number of CpG sites, as well as the observed number of CpG transition variants within each methylation bin, in either intergenic or exonic regions. To determine the expected number of transition variants at CpG sites for each methylation bin, we multiplied the total number of CpG transition variants by the fraction of CpG sites in that methylation bin compared to the whole genome. 

We observed a roughly fivefold change in the ratios of the observed to expected numbers of CpGTi mutations between high and low methylation levels. Thus, we classified CpG sites into two categories: ‘high methylation’ if the averaged methylation level exceeded 0.5, and ‘low methylation’ if the averaged methylation level was less than or equal to 0.5. We then computed the de novo mutation rates for each of the 8 CpGTi tri-nucleotide contexts separately for high and low methylation levels. When averaging these mutation rates across the 8 CpGTi tri-nucleotide contexts, we obtained CpGTi mutation rates of 1.01e-07 for high methylation and 2.264e-08 for low methylation, representing a difference of approximately one order of magnitude.

We computed average de novo mutation rates across 56 tri-nucleotide contexts with transition mutations at non-CpG sites (nonCpGTi), yielding a nonCpGTi mutation rate of 5.552e-09. Using this mutation rate, we conducted simulation of 100K independent sites according to the demographic model described earlier and then generated the allele frequency spectrum from the simulated sites. Similarly, we calculated average de novo mutation rates across 128 tri-nucleotide contexts involving transversion mutations (Tv), producing a Tv mutation rate of 2.034e-09, with which we performed the simulation and generated the AFS for Tv. For CpGTi mutations, we conducted separate simulation for 100K sites using mutation rates associated with high and low methylation levels derived previously and produced the two AFSs. To consolidate the AFS, we merged the two simulated AFSs using the known proportions of high or low methylation sites in the human genome as weights118. 

Fitting the AFS of gnomAD exome sequencing data

To find the optimal historical parameters for our demographic model under neutral evolution, we explored various parameter combinations by fitting the simulated allele frequency spectrum to that of the observed rare synonymous mutations in human populations. We conducted a grid search across a broad range of values for each of the three parameters, g ranging from 330 to 550 with increments of 20, r spanning from 20 to 110 with increments of 5, and n  (1.0,2.0,3.0,4.0,5.0).  

For each combination of the parameters, we simulated a human population from dawn to the present day, and then randomly sampled 1000 sets, each comprising 246K chromosomes, matching the sample size of gnomAD exomes. From these sets, we generated the expected AFS by averaging across these 1000 sampled sets.

We obtained human exome polymorphism data from the Genome Aggregation Database v2.1.137  (gnomad.exomes.r2.1.1.sites.vcf.bgz file), which collected the whole-exome sequencing data of 123,136 individuals from eight subpopulations around the world (http://gnomad.broadinstitute.org/). We excluded variants that do not pass filters, or have median coverage < 15, or fall within low complexity regions or segmental duplication regions (boundary of regions defined in the file downloaded from https://storage.googleapis.com/gnomad-public/release/2.0.2/README.txt).  We retained variants that are mapped to the canonical coding sequences defined by the UCSC genome browser for the hg38 build141.

We generated the allele frequency spectrum of rare synonymous variants by counting the number of synonymous variants in seven allele frequency categories, including singletons, doubletons, 3<=allele count (AC) <=4, …, and 33<=AC <=64. Variants with AC >64 were discarded as we focused on rare variants. To identify the best-fitting parameters for our model, we applied a likelihood ratio test to evaluate the goodness-of-fit of the simulated AFS to the gnomAD AFS of synonymous variants across the three mutational classes to determine the optimal parameters. The heatmap of Pearson’s chi-squared statistic (corresponding to -2*log likelihood ratio) in Extended Data Fig. 1d shows the optimal parameter combination occurs at g=530, r=30, and n=2.0. Extended Data Fig. 1a shows that the simulated AFS with this parameter combination mimics the observed gnomAD AFS. The estimate of T1=530 generations agrees with archaeology, which dates the broad adoption of agriculture to ~10,000 BC (beginning of Neolithic era). The ratio between census and effective population size is lower than expected, implying that the diversity of human population is actually quite high. Note that we also varied the number of generations during the burn-in period and found 3,500 generations achieves the best result. 

